{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sars-CoV-2-Challenge.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC9RoFWnZa4e",
        "colab_type": "text"
      },
      "source": [
        "Bloc 1: Instalació de llibreries  \n",
        "Bloc 2: Importació de llibreries  \n",
        "Bloc 3: Per treballar amb fitxers des del Drive  \n",
        "Bloc 4: Definició de funcions  \n",
        "Bloc 5: Crida de funcions  \n",
        "  \n",
        "Com fer servir:  \n",
        "- Executar bloc 1 i després bloc 2  \n",
        "- Executar bloc 4  \n",
        "SI ES VOL TREBALLAR AL DRIVE:  \n",
        "+ Executar el bloc 3 i introduïr el codi de la web\n",
        "+ Canviar les variables \"csv_datab_name\" i \"filename\" a la carpeta on hi ha la base de dades  \n",
        "SI NO:  \n",
        "+ Canviar les variables \"csv_datab_name\" i \"filename\" a la carpeta on hi ha la base de dades  \n",
        "FINALMENT:\n",
        "- Executar el bloc 5  \n",
        "- Es pot treballar amb les dades fasta al bloc 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV_rOXi0TNVq",
        "colab_type": "code",
        "outputId": "078e17de-6d64-421b-90d4-1643b6e07853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "#Bloc 1\n",
        "\n",
        "!pip3 install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.6/dist-packages (3.141.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Fetched 74.6 kB in 2s (37.4 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (81.0.4044.122-0ubuntu0.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlU7UGpC3C-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bloc 2\n",
        "\n",
        "import csv\n",
        "import timeit\n",
        "import math\n",
        "import requests\n",
        "from time import sleep\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU-G8JuIzA1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bloc 3\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmWsFSM1w8ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bloc 4\n",
        "\n",
        "def get_global_data(route):\n",
        "    #Format global_data: Accession, Length, Location, Date\n",
        "    global_data = []\n",
        "    with open(route,newline=\"\") as csvfile:\n",
        "        reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
        "        for i, row in enumerate(reader):\n",
        "            if i > 3:\n",
        "                line = ','.join(row).split(\",\")\n",
        "                if line[2].endswith(\":\"):\n",
        "                    line[2] = line[2][:-1]\n",
        "                    line[3] = line[4]\n",
        "                    line = line[:-1]\n",
        "                if line[2].startswith(\"\\\"\"):\n",
        "                    line[2] = line[2][1:]\n",
        "                if line[2] != '':\n",
        "                    global_data.append(line)\n",
        "\n",
        "    return global_data\n",
        "\n",
        "def separate_in_countries(data,mode):\n",
        "    if mode == 1:\n",
        "        countries = []\n",
        "        for row in data:\n",
        "            if not row[2] in countries:\n",
        "                countries.append(row[2])\n",
        "        separated_data = []\n",
        "        for country in countries:\n",
        "            country_line = []\n",
        "            for row in data:\n",
        "                if row[2] == country:\n",
        "                    country_line.append(row)\n",
        "            separated_data.append(country_line)\n",
        "        return separated_data\n",
        "    else:\n",
        "        separated_data = {}\n",
        "        for row in data:\n",
        "            if row[2] in separated_data.keys():\n",
        "                separated_data[row[2]].append(row)\n",
        "            else:\n",
        "                separated_data[row[2]] = [row]\n",
        "        return [separated_data[key] for key in separated_data.keys()]\n",
        "\n",
        "def country_medians(data):\n",
        "    medians = []\n",
        "    for country_data in data:\n",
        "        country_name = country_data[0][2]\n",
        "        medians.append((country_name,country_data[math.floor(len(country_data) / 2)][1],country_data[math.floor(len(country_data) / 2)][0]))\n",
        "    return medians\n",
        "\n",
        "def get_files(country_data):\n",
        "    url = \"https://www.ncbi.nlm.nih.gov/nuccore/\" + str(country_data[2]) + \".1?report=fasta\"\n",
        "    filename = str(country_data[0]) + \".fasta\"\n",
        "\n",
        "    chrome_options = webdriver.ChromeOptions()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "    driver.get(url)\n",
        "    sleep(0.2)\n",
        "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
        "\n",
        "    f = open(filename,\"w\")\n",
        "    f.write(\"\".join(soup.find(id=\"viewercontent1\").text.split(\"\\n\")[1:]))\n",
        "    f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrpoREk126OU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d1b79c4-f945-4bd0-a2e8-a774afd2721f"
      },
      "source": [
        "#Bloc 5\n",
        "\n",
        "#Ruta Joel A, l'haureu de canviar si ho voleu provar\n",
        "csv_datab_route = \"/content/drive/My Drive/Uni/Practica1-Algoritmica/all_sequences.csv\"\n",
        "file_route = \"/content/drive/My Drive/Uni/Practica1-Algoritmica/time.txt\"\n",
        "f = open(file_route,\"w\")\n",
        "\n",
        "#O(N) -> N = Numero total de mostres\n",
        "my_data = get_global_data(csv_datab_route)\n",
        "f.write(\"Get global data:\\n\")\n",
        "f.write(str(timeit.timeit(\"get_global_data(csv_datab_route)\",\"from __main__ import csv_datab_route, get_global_data\",number=1)) + \"\\n\")\n",
        "\n",
        "#O(M*N) -> M = Numero total de països\n",
        "my_countries = separate_in_countries(my_data,2)\n",
        "f.write(\"Separate in countries 1:\\n\")\n",
        "f.write(str(timeit.timeit(\"separate_in_countries(my_data,1)\",\"from __main__ import separate_in_countries,my_data\",number=1)) + \"\\n\")\n",
        "f.write(\"Separate in countries 2:\\n\")\n",
        "f.write(str(timeit.timeit(\"separate_in_countries(my_data,2)\",\"from __main__ import separate_in_countries,my_data\",number=1)) + \"\\n\")\n",
        "\n",
        "#O(M)\n",
        "medians = country_medians(my_countries)\n",
        "f.write(\"Medians:\\n\")\n",
        "f.write(str(timeit.timeit(\"country_medians(my_countries)\",\"from __main__ import country_medians,my_countries\",number=1)) + \"\\n\")\n",
        "\n",
        "#O(M)\n",
        "total_timeit = 0.0\n",
        "for data in medians:\n",
        "    get_files(data)\n",
        "    total_timeit += timeit.timeit(\"get_files(data)\",\"from __main__ import get_files,data\",number=1)\n",
        "\n",
        "f.write(\"Total file scraping: \")\n",
        "f.write(str(total_timeit))\n",
        "f.write(\"Average file scraping: \")\n",
        "f.write(str(total_timeit/len(medians)))\n",
        "\n",
        "print(\"DONE\")\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9YgrhYZzMY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bloc 6\n",
        "\n",
        "def sequence_alignment():\n",
        "  sequence_1 = \"ACCGAAC\"\n",
        "  sequence_2 = \"ACCTAAC\"\n",
        "  match = -1\n",
        "  non_match = 4\n",
        "  gap = 5\n",
        "  result = 0\n",
        "  matriu = []\n",
        "\n",
        "  #Creació matriu\n",
        "  for _ in range(len(sequence_1) + 2):\n",
        "    fila = []\n",
        "    for _ in range(len(sequence_2) + 2):\n",
        "      fila.append(0)\n",
        "    matriu.append(fila)\n",
        "\n",
        "  #Inicialització dels eixos\n",
        "  matriu[0][1] = \"-\"\n",
        "  matriu[1][0] = \"-\"\n",
        "\n",
        "  for i in range(len(sequence_1)):\n",
        "    matriu[i + 2][0] = sequence_1[i]\n",
        "  for i in range(len(sequence_2)):\n",
        "    matriu[0][i + 2] = sequence_2[i]\n",
        "\n",
        "  #Omplim la matriu\n",
        "  for i = 1 in range(len(sequence_1)):\n",
        "    for j = 0 in range(len(sequence_2)):\n",
        "      if (sequence_1[i] == sequence_2[j]):"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}